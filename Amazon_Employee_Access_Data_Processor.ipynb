{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Amazon Employee Access Data Processor",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/atasipanda/fair_bipartite_matching/blob/main/Amazon_Employee_Access_Data_Processor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "This is an online editor. To see the outputs, hit **Runtime > Run all** option"
      ],
      "metadata": {
        "id": "4VgGjz1JyCVS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\"\"\"\n",
        "Function to create a random ranking of platforms\n",
        "\"\"\"\n",
        "def create_ranking(train_df):\n",
        "    platforms = list(train_df.RESOURCE.unique())\n",
        "    platform_ranks = {}\n",
        "    random_platforms = random.sample(platforms, len(platforms))\n",
        "    for i, p in enumerate(random_platforms):\n",
        "        platform_ranks[p] = i + 1\n",
        "    return platform_ranks"
      ],
      "metadata": {
        "id": "gMXkmjJD7jbh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Function to calculate Delta value\n",
        "Delta is the most number of groups an item can belong to\n",
        "\"\"\"\n",
        "def calc_Delta(item_group_df):\n",
        "  Delta = 0\n",
        "  item_groups = {}\n",
        "  for ig in item_group_df.to_dict(orient='records'):\n",
        "    item_groups[ig[\"MGR_ID\"]] = ig[\"ROLE_FAMILY\"]\n",
        "    if len(ig[\"ROLE_FAMILY\"]) > Delta:\n",
        "      Delta = len(ig[\"ROLE_FAMILY\"])\n",
        "  return item_groups, Delta\n"
      ],
      "metadata": {
        "id": "I5EDwnhABjZA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Key: Resource\n",
        "Value: Another dictionary say X\n",
        "For X\n",
        "Key: RoleFamily\n",
        "Value: count of MGR_IDs in this RoleFamily that made a request for this particular Resource\n",
        "\n",
        "Function to assign upper bounds per platform per group\n",
        "\"\"\"\n",
        "from collections import defaultdict\n",
        "def assign_platform_bounds(data, n, m, g, k, item_groups):\n",
        "  platform_bounds = defaultdict(dict)\n",
        "  b = (k*n)/(m*g)\n",
        "  spots = 0\n",
        "  for r in data:\n",
        "    role_fam = item_groups[r['MGR_ID']]\n",
        "    for role in role_fam:\n",
        "      if role not in platform_bounds[r[\"RESOURCE\"]]: #and spots < n - 1:\n",
        "        platform_bounds[r[\"RESOURCE\"]][role] = b\n",
        "  return platform_bounds"
      ],
      "metadata": {
        "id": "5PY3eE_mEVuD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Creating edges from the data\n",
        "\"\"\"\n",
        "def create_edges(data, platform_ranks):\n",
        "  edge_list = []\n",
        "  item_edge_rank_dict = {}\n",
        "  for r in data:\n",
        "    edge_list.append((r[\"MGR_ID\"], r[\"RESOURCE\"]))\n",
        "    edge_rank = platform_ranks[r[\"RESOURCE\"]]\n",
        "    if r[\"MGR_ID\"] in item_edge_rank_dict:\n",
        "      item_edge_rank_dict[r[\"MGR_ID\"]].append([(r[\"MGR_ID\"], r[\"RESOURCE\"]), edge_rank])\n",
        "    else:\n",
        "      item_edge_rank_dict[r[\"MGR_ID\"]] = []\n",
        "      item_edge_rank_dict[r[\"MGR_ID\"]].append([(r[\"MGR_ID\"], r[\"RESOURCE\"]), edge_rank])\n",
        "  return edge_list, item_edge_rank_dict"
      ],
      "metadata": {
        "id": "8mEErXdcJDmY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy import linalg, optimize\n",
        "from scipy.optimize import linprog\n",
        "import copy"
      ],
      "metadata": {
        "id": "q0m8JePdELJ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Finding a greedy maximal matching\n",
        "\"\"\"\n",
        "def find_maximal_matching(item_groups, platform_bounds, edge_list):\n",
        "    A = copy.deepcopy(item_groups)\n",
        "    P = copy.deepcopy(platform_bounds)\n",
        "    E = copy.deepcopy(edge_list)\n",
        "    M = []\n",
        "    matched_nodes = set([])\n",
        "    invalid = 0\n",
        "    coef=[]\n",
        "    count = 0\n",
        "    for e in E:\n",
        "        # print E[i]\n",
        "        if e == 0:\n",
        "          count = count+1\n",
        "        coef.append(0)\n",
        "    for i, e in enumerate(E):\n",
        "        #print(e)\n",
        "        if e == 0: #or x[i] <= norm:\n",
        "            continue\n",
        "        groups = A.get(e[0])\n",
        "        for g in groups:\n",
        "            if e[0] in matched_nodes:\n",
        "                invalid = 1\n",
        "                break\n",
        "            if P.get(e[1]).get(g) <= 0:\n",
        "                invalid = 1\n",
        "                break\n",
        "            P[e[1]][g] = P[e[1]][g] - 1\n",
        "        if invalid == 1:\n",
        "            invalid = 0\n",
        "            continue\n",
        "        M.append(e)\n",
        "        coef[i] = 1\n",
        "        matched_nodes.add(e[0])\n",
        "    #print(coef)\n",
        "    # return M, coef\n",
        "    return coef"
      ],
      "metadata": {
        "id": "E4t9sx6HxSwM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.optimize import linprog\n",
        "\"\"\"\n",
        "The lp that is solved in step 1 of algorithm 4\n",
        "\"\"\"\n",
        "def delta_lp(item_groups, platform_bounds, edge_list, item_edge_rank_dict):\n",
        "    A = copy.deepcopy(item_groups)\n",
        "    P = copy.deepcopy(platform_bounds)\n",
        "    E = copy.deepcopy(edge_list)\n",
        "    obj = []\n",
        "    lhs = []\n",
        "    rhs = []\n",
        "    platform_groups = {}\n",
        "    zero_list = []\n",
        "    one_list = []\n",
        "    bounds = []\n",
        "    m = len(platform_bounds)\n",
        "    for e in E:\n",
        "        zero_list.append(0)\n",
        "        #bounds.append((0, 1))  # lower and upper bounds for each x value\n",
        "    for item in item_edge_rank_dict:\n",
        "      coef = copy.deepcopy(zero_list)\n",
        "      if len(item_edge_rank_dict[item]) > 1:\n",
        "        edge_rank_list = copy.deepcopy(item_edge_rank_dict[item])\n",
        "        edge_rank_list.sort(key = lambda x: x[1])\n",
        "      else:\n",
        "        edge_rank_list = item_edge_rank_dict[item]\n",
        "      for er in edge_rank_list:\n",
        "        edge = er[0]\n",
        "        rank = er[1]\n",
        "        pos = E.index(edge)\n",
        "        coef[pos] = -1\n",
        "        lb = rank/(2*m)\n",
        "        lhs.append(coef) #individual fairness constraints\n",
        "        rhs.append(-1*lb) \n",
        "        # print(sum(coef))\n",
        "        # print(-1*lb)\n",
        "    for i, e in enumerate(E):\n",
        "        one_list = copy.deepcopy(zero_list)\n",
        "        one_list[i] = 1 #enforcing upper bound one more time\n",
        "        lhs.append(one_list)\n",
        "        rhs.append(1)\n",
        "        obj.append(-1)\n",
        "        initial_coef = list(zero_list)\n",
        "        initial_coef[i] = 1\n",
        "        item = e[0]\n",
        "        platform = e[1]\n",
        "        groups = A.get(item)\n",
        "        for group in groups:\n",
        "            pg = (platform, group)\n",
        "            if pg not in platform_groups:\n",
        "                platform_groups[pg] = list(initial_coef)\n",
        "                # rhs.append(P.get(platform).get(group))\n",
        "            else:\n",
        "                platform_groups[pg][i] = 1\n",
        "    for pg in platform_groups:\n",
        "        #if P.get(pg[0]).get(pg[1])==None:\n",
        "        #print(pg)\n",
        "        #print(P.get(pg[0]))\n",
        "        lhs.append(platform_groups[pg])\n",
        "        rhs.append(P.get(pg[0]).get(pg[1]))\n",
        "    opt = linprog(c=obj, A_ub=lhs, b_ub=rhs, bounds=(0,1))\n",
        "    #print(sum(opt.x))\n",
        "    return list(opt.x)\n",
        "    #return sum(opt.x)"
      ],
      "metadata": {
        "id": "6NnXzoF_EbCL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\"\"\" \n",
        "Algorithm 4\n",
        "\"\"\"\n",
        "def delta_log_alg(item_groups, platform_bounds, edge_list, item_edge_rank_dict, f):\n",
        "    #print(E)\n",
        "    A = copy.deepcopy(item_groups)\n",
        "    P = copy.deepcopy(platform_bounds)\n",
        "    E = copy.deepcopy(edge_list)\n",
        "    d = len(E)\n",
        "    x = delta_lp(A, P, E, item_edge_rank_dict)\n",
        "    norm = sum(x)\n",
        "    UB = norm\n",
        "    match_count = 0\n",
        "    alpha = []\n",
        "    cost = 0\n",
        "    while norm > f:\n",
        "        norm_i=0\n",
        "        for i, val in enumerate(x):\n",
        "            if val == 0:\n",
        "                E[i] = 0\n",
        "        M = find_maximal_matching(A, P, E, f, x)\n",
        "        # print('matching')\n",
        "        # print(M)\n",
        "        #if sum(M) == 0:\n",
        "          #break\n",
        "        #if sum(M) >= max:\n",
        "          #max = sum(M)\n",
        "        x_modified = [x[i] for i, e in enumerate(x) if x[i] != 0 and M[i] != 0]\n",
        "        alpha_i = min(x_modified)\n",
        "        #print(\"min value\")\n",
        "        #print(alpha_i)\n",
        "        alpha.append(alpha_i)\n",
        "        cost = cost + alpha_i*sum(M)\n",
        "        for i, val in enumerate(x):\n",
        "            if val != 0:\n",
        "                x[i] = val - alpha_i * M[i]\n",
        "        norm_i = sum(x)\n",
        "        #if norm_i == norm:\n",
        "          #print(\"residue before f\")\n",
        "          #print(norm_i)\n",
        "          #break\n",
        "        #else:\n",
        "        norm = norm_i\n",
        "        # if norm <= f:\n",
        "        #   print(\"residue\")\n",
        "        #   print(norm_i)\n",
        "        match_count = match_count + 1\n",
        "    denominator = sum(alpha)\n",
        "    if denominator!=0:\n",
        "      output = cost/denominator\n",
        "    else:\n",
        "      print('Division by 0')\n",
        "      output = cost\n",
        "    return output, UB, match_count"
      ],
      "metadata": {
        "id": "YOE01EQ8xrnx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from io import StringIO\n",
        "import re\n",
        "from itertools import chain as flatten\n",
        "import networkx as nx\n",
        "from functools import partial\n",
        "import holoviews as hv\n",
        "import cvxpy as cp\n",
        "import numpy as np\n",
        "import math\n",
        "from time import process_time\n",
        "def main_function():\n",
        "    df = pd.read_csv('emp_access_challenge_free.csv')  # load file as a data frame\n",
        "    i = 1\n",
        "    eps = 0.001\n",
        "    output_file = 'result/output_1000.txt'  # replace with the file name you want\n",
        "    while i <= 10:\n",
        "        init_train_df = df.sample(n=1000)  # increase `n` as per sample size\n",
        "        train_df = init_train_df.\\\n",
        "            drop_duplicates(subset=[\"MGR_ID\", \"RESOURCE\",\"ROLE_FAMILY\"], keep=False)   # dropping any duplicate rows\n",
        "        final_edges = len(train_df)  # number of edges after duplicate rows are cleaned out\n",
        "        file_name = 'result/emp_access_1000_'+ str(i) + '.csv'  # replace with the file name you want\n",
        "        train_df.to_csv(file_name)  # saving the sample to a file\n",
        "        g = train_df.ROLE_FAMILY.nunique()  # total number of unique groups\n",
        "        n = train_df.MGR_ID.nunique()   # total number of unique items\n",
        "        m = train_df.RESOURCE.nunique()  # total number of unique platforms\n",
        "        k = math.ceil(m*g/n)   # factor to calculate the upper bound per group per platform\n",
        "        platform_ranks = create_ranking(train_df)\n",
        "        platforms_file_name = 'result/platform_ranks_1000_' + str(i) + '.txt'\n",
        "        with open(platforms_file_name, 'w') as fp:  # storing the platform ranking\n",
        "            for pr in platform_ranks:\n",
        "                fp.write(str(pr) + \":\" + str(platform_ranks[pr])+\"\\n\")\n",
        "        item_group_df = train_df.groupby('MGR_ID')['ROLE_FAMILY'].apply(lambda x: list(np.unique(x))).apply(list).reset_index()\n",
        "        item_groups, Delta = calc_Delta(item_group_df)\n",
        "        data = train_df.to_dict(orient='records')\n",
        "        platform_bounds = assign_platform_bounds(data, n, m, g, k, item_groups)\n",
        "        edge_list, item_edge_rank_dict = create_edges(data, platform_ranks)\n",
        "        start_time = process_time()\n",
        "        output, UB, match_count = delta_log_alg(item_groups, platform_bounds, edge_list, item_edge_rank_dict, eps)\n",
        "        runtime = process_time() - start_time   # calculating the runtime\n",
        "        log_val = math.log2(n/eps)\n",
        "        approx = 2*(Delta+1)*(log_val+1)\n",
        "        act = UB/output\n",
        "        with open(output_file, 'a') as fp:  # storing the parameters and output\n",
        "            fp.write(\"iteration: \" + str(i) + \"\\n\")\n",
        "            fp.write(\"items: \" + str(n) + \", platforms: \" + str(m) + \", groups: \"+ str(g) + \", edges: \" + str(final_edges) +\", UB: \" + str(UB) + \", SOL: \" + str(output) + \"\\n\")\n",
        "            fp.write(\"Delta: \" + str(Delta) + \", UB/SOL: \" + str(act) + \", approx:\" + str(approx) +  \", # of matchings:\" + str(match_count) + \", run-time: \" + str(runtime) + \"\\n\")\n",
        "        i = i+1\n"
      ],
      "metadata": {
        "id": "H6Z-z3ctxz6Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "txI2n6zvzlFh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "main_function()"
      ],
      "metadata": {
        "id": "RyONYqEU2-9o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "!zip -r /content/result_1000.zip /content/result\n",
        "files.download('/content/result_1000.zip')"
      ],
      "metadata": {
        "id": "1OuwD-X8qspd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}